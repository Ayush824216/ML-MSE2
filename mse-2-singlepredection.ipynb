{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":103417,"databundleVersionId":12473839,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score, log_loss\n\n# ==========================================\n# 1. USER CONFIGURATION (EDIT THIS PART ONLY)\n# ==========================================\nTRAIN_PATH = \"/kaggle/input/ai-201-b-mse-2-aiml-a/train.csv\"  # Path to training file\nTEST_PATH = \"/kaggle/input/ai-201-b-mse-2-aiml-a/test.csv\"    # Path to test file\nTARGET_COL = \"NObeyesdad\"                  # Name of the column you want to predict\nID_COL = \"id\"                          # Name of the ID column (to be excluded from training)\nOUTPUT_FILE = \"Name.csv\"         # Name of the output file\n# ==========================================\n\n# 2. Load Data\nprint(\"Loading data...\")\ntrain_data = pd.read_csv(TRAIN_PATH)\ntest_data = pd.read_csv(TEST_PATH)\n\nprint(f\"Train shape: {train_data.shape}\")\nprint(f\"Test shape: {test_data.shape}\")\n\n# 3. Handle ID Columns\n# Save test IDs for submission later\ntest_ids = test_data[ID_COL]\n\n# Drop ID from training and testing sets to prevent overfitting\nif ID_COL in train_data.columns:\n    train_data = train_data.drop(columns=[ID_COL])\nif ID_COL in test_data.columns:\n    test_data = test_data.drop(columns=[ID_COL])\n\n# 4. Separate Features (X) and Target (y)\nX = train_data.drop(columns=[TARGET_COL])\ny = train_data[TARGET_COL]\n\n# 5. Dynamic Feature Selection\n# Automatically detect which columns are numbers and which are categories\ncat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\nnum_cols = X.select_dtypes(include=['number']).columns.tolist()\n\nprint(f\"\\nDetected {len(cat_cols)} categorical columns: {cat_cols}\")\nprint(f\"Detected {len(num_cols)} numerical columns: {num_cols}\")\n\n# 6. Impute Missing Values (Preprocessing Step 1)\n# Fill numbers with MEAN, categories with MODE\nprint(\"\\nImputing missing values...\")\n\n# Fill Numerical\nif num_cols:\n    mean_vals = X[num_cols].mean()\n    X[num_cols] = X[num_cols].fillna(mean_vals)\n    test_data[num_cols] = test_data[num_cols].fillna(mean_vals)\n\n# Fill Categorical\nif cat_cols:\n    # We take the first mode ([0]) in case there's a tie\n    mode_vals = X[cat_cols].mode().iloc[0]\n    X[cat_cols] = X[cat_cols].fillna(mode_vals)\n    test_data[cat_cols] = test_data[cat_cols].fillna(mode_vals)\n\n# 7. Visualization (Optional)\n# Plotting correlation for numerical features\nif len(num_cols) > 1:\n    plt.figure(figsize=(10, 6))\n    sns.heatmap(train_data[num_cols].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n    plt.title(\"Feature Correlation Heatmap\")\n    plt.show()\n\n# Plot Class Distribution\nplt.figure(figsize=(6, 4))\nsns.countplot(x=TARGET_COL, data=train_data)\nplt.title(f\"Class Distribution for {TARGET_COL}\")\nplt.show()\n\n# 8. Define Transformation Pipeline (Preprocessing Step 2)\npreprocessor = ColumnTransformer(transformers=[\n    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n    ('num', StandardScaler(), num_cols)\n])\n\n# 9. Train/Validation Split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# 10. Fit Preprocessor\nprint(\"\\nTransforming data...\")\nX_train_pre = preprocessor.fit_transform(X_train)\nX_val_pre = preprocessor.transform(X_val)\ntest_data_pre = preprocessor.transform(test_data)\n\n# 11. Train Model\nprint(\"\\nTraining Random Forest...\")\nrfc = RandomForestClassifier(n_estimators=1000, random_state=42, class_weight='balanced')\nrfc.fit(X_train_pre, y_train)\n\n# 12. Evaluate\nprint(\"Evaluating model...\")\nval_proba = rfc.predict_proba(X_val_pre)\n\n# Calculate Score (handling multiclass automatically)\ntry:\n    roc = roc_auc_score(y_val, val_proba, multi_class='ovr', average='macro')\n    loss = log_loss(y_val, val_proba)\n    print(f\"Validation ROC AUC: {roc:.4f}\")\n    print(f\"Validation Log Loss: {loss:.4f}\")\nexcept ValueError as e:\n    print(f\"Could not calculate some metrics (likely binary vs multiclass mismatch): {e}\")\n\n# 13. Generate Submission\nprint(\"\\nGenerating submission...\")\n\ntest_pred_labels = rfc.predict(test_data_pre)\n\nsubmission_df = pd.DataFrame({\n    ID_COL: test_ids,\n    TARGET_COL: test_pred_labels\n})\n\nsubmission_df.to_csv(OUTPUT_FILE, index=False)\nprint(f\"Submission saved to {OUTPUT_FILE}\")\nprint(submission_df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}